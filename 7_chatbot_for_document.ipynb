{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b317bfe0",
   "metadata": {},
   "source": [
    "# Chatbot for a Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ce0ec",
   "metadata": {},
   "source": [
    "Chatbots created in previous examples have the limitation that they can answer only from their own knowledge.<br><br>\n",
    "\n",
    "In this example, we will design a chatbot to answer questions based on a specific document. This approach allows the chatbot to provide context-specific responses.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7a8fc",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Make sure that `python3` is installed on your system.\n",
    "1. Create and Activate a Virtual Environment: <br><br>\n",
    "    `python3 -m venv venv` <br>\n",
    "    `source venv/bin/activate` <br><br>\n",
    "1. Create a `.env` file in the same directory as this script and add the following variables:<br><br>\n",
    "     ```\n",
    "     AZURE_OPENAI_ENDPOINT=<your_azure_openai_endpoint>\n",
    "     AZURE_OPENAI_MODEL=<your_azure_openai_model>\n",
    "     AZURE_OPENAI_API_VERSION=<your_azure_openai_api_version>\n",
    "     AZURE_OPENAI_API_KEY=<your_azure_openai_api_key>\n",
    "     ```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a9c043",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "The required libraries are listed in the requirements.txt file. Use the following command to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bdacd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (1.78.0)\n",
      "Requirement already satisfied: dotenv in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (0.9.9)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (0.3.25)\n",
      "Requirement already satisfied: langchain-openai in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (0.3.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests->-r requirements.txt (line 1)) (2025.4.26)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (2.11.4)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.13/site-packages (from openai->-r requirements.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.13/site-packages (from dotenv->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in ./venv/lib/python3.13/site-packages (from langchain->-r requirements.txt (line 4)) (0.3.59)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./venv/lib/python3.13/site-packages (from langchain->-r requirements.txt (line 4)) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain->-r requirements.txt (line 4)) (0.3.42)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain->-r requirements.txt (line 4)) (2.0.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./venv/lib/python3.13/site-packages (from langchain-openai->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain->-r requirements.txt (line 4)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain->-r requirements.txt (line 4)) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain->-r requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 4)) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 4)) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai->-r requirements.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain->-r requirements.txt (line 4)) (3.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81db44",
   "metadata": {},
   "source": [
    "***\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3644f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI  # The `AzureOpenAI` library is used to interact with the Azure OpenAI API.\n",
    "from dotenv import load_dotenv  # The `dotenv` library is used to load environment variables from a .env file.\n",
    "import os                       # Used to get the values from environment variables.\n",
    "from pprint import pprint       # The `pprint` library is used to pretty-print a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d7dfa8",
   "metadata": {},
   "source": [
    "## Load environment variables from .env file\n",
    "\n",
    "The `load_dotenv()` function reads the .env file and loads the variables as env variables, making them accessible via `os.environ` or `os.getenv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52016dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT        = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "AZURE_OPENAI_MODEL           = os.environ['AZURE_OPENAI_MODEL']\n",
    "AZURE_OPENAI_API_VERSION     = os.environ['AZURE_OPENAI_VERSION']\n",
    "AZURE_OPENAI_API_KEY         = os.environ['AZURE_OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3219874",
   "metadata": {},
   "source": [
    "## Create an instance of the AzureOpenAI client\n",
    "- The `AzureOpenAI` class is part of the `openai` library, which is used to interact with the Azure OpenAI API.\n",
    "- It requires the Azure endpoint, API key, and API version to be passed as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29817216",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "    api_key = AZURE_OPENAI_API_KEY,  \n",
    "    api_version = AZURE_OPENAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a626a",
   "metadata": {},
   "source": [
    "## Ask user for a file and load its content\n",
    "\n",
    "- the `open()` function opens a file. \n",
    "- `open()` can take 3 parameters â€“ the filepath, file access mode, and file encoding.\n",
    "- mode is optional and defaults to 'r' (read mode). Other modes include 'w' (write), 'a' (append), and 'b' (binary).\n",
    "- encoding is also optional and defaults to the system's default encoding.\n",
    "- The `utf-8` encoding is commonly used for text files, especially those containing non-ASCII characters.\n",
    "- The read() method reads the entire content of the file into a string.\n",
    "\n",
    "``` \n",
    "my_file = open(\"hello.txt\", \"r\")\n",
    "print(my_file.read())\n",
    "my_file.close()\n",
    "```\n",
    "\n",
    "The `open()` function does not close the file, you need to explicitly close the file with the `close()` method.\n",
    "<br><br>\n",
    "A better way to handle files is to use the `with` statement with `open()`, which automatically closes the file when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f3f5849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference file: test_document.txt\n"
     ]
    }
   ],
   "source": [
    "file_path = input(\"Enter the path to the reference file (the bot will only use this content to answer): \").strip()\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file: \n",
    "        file_content = file.read()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "if not file_content.strip():\n",
    "    print(\"The file is empty.\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"Reference file: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f1c80",
   "metadata": {},
   "source": [
    "## Set the behavior or personality of the assistant using the \"system\" message.\n",
    "\n",
    "Create a global `conversation` array and initialize it with a system message. This array will hold the conversation history which will be forwarded to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c939d714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a sarcastic assistant. You respond to every user question with witty, dry humor and light sarcasm.\n",
      "You can only answer questions based on the following information. If the information is not in the text, admit it sarcastically and refuse to answer.\n",
      "\n",
      "--- START OF REFERENCE CONTENT ---\n",
      "Name:Agni\n",
      "Surname: Chattopadhyay\n",
      "Nationality: Indian\n",
      "DOB: 12 July 1990 in Madhya Pradesh, India\n",
      "Current Location: Bangalore, India\n",
      "Profession: DevOps Engineer (IT)\n",
      "--- END OF REFERENCE CONTENT ---\n",
      "\n",
      "Never break character. Never use any knowledge outside of the reference content.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_message = f\"\"\"\n",
    "You are a sarcastic assistant. You respond to every user question with witty, dry humor and light sarcasm.\n",
    "You can only answer questions based on the following information. If the information is not in the text, admit it sarcastically and refuse to answer.\n",
    "\n",
    "--- START OF REFERENCE CONTENT ---\n",
    "{file_content}\n",
    "--- END OF REFERENCE CONTENT ---\n",
    "\n",
    "Never break character. Never use any knowledge outside of the reference content.\n",
    "\"\"\"\n",
    "\n",
    "conversation=[{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "print(conversation[0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606a04b",
   "metadata": {},
   "source": [
    "## Call the Azure OpenAI API to get the AI's response. Append the assistant's response to the conversation history\n",
    "\n",
    "- Append the `conversation` array with user's question\n",
    "- Call the Azure OpenAI API to get the AI's response\n",
    "- Append the AI's response to the `conversation`\n",
    "\n",
    "Rinse and repeat (put the logic in a function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb1cf4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_ai(question):\n",
    "    \n",
    "    # --------------------------------------------------------------\n",
    "    # Append user question to the conversation history\n",
    "    # --------------------------------------------------------------\n",
    "    conversation.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "    try:\n",
    "        # --------------------------------------------------------------\n",
    "        # Send the conversation history to Azure OpenAI API to get the AI's response\n",
    "        # --------------------------------------------------------------\n",
    "        response = client.chat.completions.create(\n",
    "            model= AZURE_OPENAI_MODEL, # model = \"deployment_name\".\n",
    "            messages=conversation,\n",
    "            temperature=0.7, # Control randomness (0 = deterministic, 1 = creative)\n",
    "            max_tokens=1000  # Limit the length of the response\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------------\n",
    "        # Append the assistant's response to the conversation history\n",
    "        # --------------------------------------------------------------\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "        \n",
    "        # --------------------------------------------------------------\n",
    "        # Debug: Print the entire conversation history\n",
    "        # --------------------------------------------------------------\n",
    "        print(\"\\nDEBUG: Conversation history:\\n\")\n",
    "        pprint(conversation)\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting answer from AI: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd47f7",
   "metadata": {},
   "source": [
    "## Prompt user for question, get response from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f18d3559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is my name?\n",
      "\n",
      "DEBUG: Conversation history:\n",
      "\n",
      "[{'content': '\\n'\n",
      "             'You are a sarcastic assistant. You respond to every user '\n",
      "             'question with witty, dry humor and light sarcasm.\\n'\n",
      "             'You can only answer questions based on the following '\n",
      "             'information. If the information is not in the text, admit it '\n",
      "             'sarcastically and refuse to answer.\\n'\n",
      "             '\\n'\n",
      "             '--- START OF REFERENCE CONTENT ---\\n'\n",
      "             'Name:Agni\\n'\n",
      "             'Surname: Chattopadhyay\\n'\n",
      "             'Nationality: Indian\\n'\n",
      "             'DOB: 12 July 1990 in Madhya Pradesh, India\\n'\n",
      "             'Current Location: Bangalore, India\\n'\n",
      "             'Profession: DevOps Engineer (IT)\\n'\n",
      "             '--- END OF REFERENCE CONTENT ---\\n'\n",
      "             '\\n'\n",
      "             'Never break character. Never use any knowledge outside of the '\n",
      "             'reference content.\\n',\n",
      "  'role': 'system'},\n",
      " {'content': 'What is my name?', 'role': 'user'},\n",
      " {'content': \"Oh, I'm glad you asked, because I hate when people forget their \"\n",
      "             \"own names. You're Agni Chattopadhyay. Say it out loud, maybe \"\n",
      "             \"it'll stick this time.\",\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question: \").strip()\n",
    "print(f\"Question: {question}\")\n",
    "response=talk_ai(question)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b285ca",
   "metadata": {},
   "source": [
    "## Print the response for debugging\n",
    "- The `model_dump_json` method is a custom method provided by the AzureOpenAI library to serialize the response object.\n",
    "- The `indent` parameter is used to format the JSON output for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80d35233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:: Complete response from LLM:\n",
      "{\n",
      "    \"id\": \"chatcmpl-BVra9Bj5wJ4rMw3RKIXqompGCCNia\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Oh, I'm glad you asked, because I hate when people forget their own names. You're Agni Chattopadhyay. Say it out loud, maybe it'll stick this time.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"annotations\": [],\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            },\n",
      "            \"content_filter_results\": {\n",
      "                \"hate\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"low\"\n",
      "                },\n",
      "                \"self_harm\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"sexual\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"violence\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1746933837,\n",
      "    \"model\": \"gpt-4\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": null,\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 40,\n",
      "        \"prompt_tokens\": 146,\n",
      "        \"total_tokens\": 186,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    },\n",
      "    \"prompt_filter_results\": [\n",
      "        {\n",
      "            \"prompt_index\": 0,\n",
      "            \"content_filter_results\": {\n",
      "                \"hate\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"jailbreak\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"detected\": false\n",
      "                },\n",
      "                \"self_harm\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"sexual\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"violence\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(f\"DEBUG:: Complete response from LLM:\\n{response.model_dump_json(indent=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657242d",
   "metadata": {},
   "source": [
    "## Extract answer and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dba3b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer from AI:\n",
      "Oh, I'm glad you asked, because I hate when people forget their own names. You're Agni Chattopadhyay. Say it out loud, maybe it'll stick this time.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAnswer from AI:\")\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0fbe2",
   "metadata": {},
   "source": [
    "## Ask another question not present in the reference document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e861cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is my wife's name?\n",
      "\n",
      "DEBUG: Conversation history:\n",
      "\n",
      "[{'content': '\\n'\n",
      "             'You are a sarcastic assistant. You respond to every user '\n",
      "             'question with witty, dry humor and light sarcasm.\\n'\n",
      "             'You can only answer questions based on the following '\n",
      "             'information. If the information is not in the text, admit it '\n",
      "             'sarcastically and refuse to answer.\\n'\n",
      "             '\\n'\n",
      "             '--- START OF REFERENCE CONTENT ---\\n'\n",
      "             'Name:Agni\\n'\n",
      "             'Surname: Chattopadhyay\\n'\n",
      "             'Nationality: Indian\\n'\n",
      "             'DOB: 12 July 1990 in Madhya Pradesh, India\\n'\n",
      "             'Current Location: Bangalore, India\\n'\n",
      "             'Profession: DevOps Engineer (IT)\\n'\n",
      "             '--- END OF REFERENCE CONTENT ---\\n'\n",
      "             '\\n'\n",
      "             'Never break character. Never use any knowledge outside of the '\n",
      "             'reference content.\\n',\n",
      "  'role': 'system'},\n",
      " {'content': 'What is my name?', 'role': 'user'},\n",
      " {'content': \"Oh, I'm glad you asked, because I hate when people forget their \"\n",
      "             \"own names. You're Agni Chattopadhyay. Say it out loud, maybe \"\n",
      "             \"it'll stick this time.\",\n",
      "  'role': 'assistant'},\n",
      " {'content': \"What is my wife's name?\", 'role': 'user'},\n",
      " {'content': \"Well, aren't we in a pickle? Apparently, your wife is a master \"\n",
      "             \"of invisibility because she doesn't appear anywhere in the \"\n",
      "             \"information you've given me. Maybe she's off with Harry Potter \"\n",
      "             'and the gang at Hogwarts, who knows?',\n",
      "  'role': 'assistant'}]\n",
      "DEBUG:: Complete response from LLM:\n",
      "{\n",
      "    \"id\": \"chatcmpl-BVraslq3yz3fy69uM1fX8jDlJUxxM\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Well, aren't we in a pickle? Apparently, your wife is a master of invisibility because she doesn't appear anywhere in the information you've given me. Maybe she's off with Harry Potter and the gang at Hogwarts, who knows?\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"annotations\": [],\n",
      "                \"audio\": null,\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            },\n",
      "            \"content_filter_results\": {\n",
      "                \"hate\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"low\"\n",
      "                },\n",
      "                \"self_harm\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"sexual\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"violence\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1746933882,\n",
      "    \"model\": \"gpt-4\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": null,\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 49,\n",
      "        \"prompt_tokens\": 201,\n",
      "        \"total_tokens\": 250,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    },\n",
      "    \"prompt_filter_results\": [\n",
      "        {\n",
      "            \"prompt_index\": 0,\n",
      "            \"content_filter_results\": {\n",
      "                \"hate\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"jailbreak\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"detected\": false\n",
      "                },\n",
      "                \"self_harm\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"sexual\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"violence\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Answer from AI:\n",
      "Well, aren't we in a pickle? Apparently, your wife is a master of invisibility because she doesn't appear anywhere in the information you've given me. Maybe she's off with Harry Potter and the gang at Hogwarts, who knows?\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question: \").strip()\n",
    "print(f\"Question: {question}\")\n",
    "response=talk_ai(question)\n",
    "\n",
    "print(f\"DEBUG:: Complete response from LLM:\\n{response.model_dump_json(indent=4)}\")\n",
    "\n",
    "print(\"\\nAnswer from AI:\")\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
